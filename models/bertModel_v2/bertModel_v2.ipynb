{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Model V2\n",
    "### Operating with GPU support on Mac M2 Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In VScode, if the kernel doesnt show up automatically, go to VS code settings->user->extensions->python->Env File. Enter ${workspaceFolder}/venv/.env into the path.\n",
    "\n",
    "Go back to this notebook, select kernel again. It should be under the Jupyter Kernel... choice, and its called venv.\n",
    "\n",
    "Make sure to activate it in terminal in the 'bertModel_v2' folder using the command $source venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachseletsky/Documents/CS4641-Project/models/bertModel_v2/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confirm GPU support</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "global device\n",
    "#Check if GPU support is enabled. returns: device object, msg\n",
    "def check_device():\n",
    "    msg = ''\n",
    "    if torch.backends.mps.is_available():\n",
    "        mps_device = torch.device(\"mps\")\n",
    "        x = torch.ones(1, device=mps_device)    \n",
    "        msg=x\n",
    "    else:\n",
    "        msg=\"MPS device not found.\"\n",
    "    return msg\n",
    "print(check_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertModel(Dataset):\n",
    "    def __init__(self, dataPath= '../../sample.csv', testSize=0.2, randomState=42):\n",
    "        #data\n",
    "        self.datasetPath = dataPath\n",
    "        self.dataFrame = pd.read_csv(dataPath)\n",
    "        self.texts = self.dataFrame['text'].tolist()\n",
    "        self.labels = self.dataFrame['label'].tolist()\n",
    "\n",
    "\n",
    "        #parameters\n",
    "        self.batch_size = 8\n",
    "        self.max_len = 16\n",
    "        self.epochs = 4\n",
    "        \n",
    "        #hyperparameters\n",
    "        self.test_size = testSize\n",
    "        self.random_state = randomState\n",
    "        self.learn_rate = 2e-5\n",
    "\n",
    "        # datasets\n",
    "        self.train_texts, self.val_texts, self.train_labels, self.val_labels = None, None, None, None\n",
    "        \n",
    "        #device\n",
    "        self.device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "        #objects\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "        \n",
    "        self.model.to(\"mps\")\n",
    "        self.train_loader = None\n",
    "        self.val_dataset = None\n",
    "\n",
    "\n",
    "    # Define a custom dataset class\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, texts, labels, tokenizer, max_len):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_len = max_len\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            text = str(self.texts[idx])\n",
    "            label = self.labels[idx]\n",
    "\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            input_ids = encoding['input_ids'].flatten()\n",
    "            attention_mask = encoding['attention_mask'].flatten()\n",
    "\n",
    "            input_ids = input_ids.to(\"mps\") if torch.backends.mps.is_available() else input_ids\n",
    "            attention_mask = attention_mask.to(\"mps\") if torch.backends.mps.is_available() else attention_mask\n",
    "\n",
    "\n",
    "            return {\n",
    "                'text': text,\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'label': torch.tensor(label, dtype=torch.long, device=\"mps\")\n",
    "            }\n",
    "        \n",
    "    #metric stuff\n",
    "    def calc_metrics(self, data, prevAvg, prevStdDev):\n",
    "\n",
    "        data_array = np.array(data)\n",
    "\n",
    "        avg = np.average(data_array)\n",
    "        std_dev = np.std(data_array)\n",
    "\n",
    "        return avg, std_dev\n",
    "\n",
    "    \n",
    "    #set parameters, returns bool == success of func\n",
    "    def setParameters(self, batchSize, maxLen, n_epochs):\n",
    "\n",
    "        self.batch_size = batchSize\n",
    "        self.max_len = maxLen\n",
    "        self.epochs = n_epochs\n",
    "\n",
    "        print(f\"\\nParameters Set!\\n------------------\\nbatch_size:{self.batch_size}\\nmax_len:{self.max_len}\\nepochs:{self.epochs}\")\n",
    "        return True\n",
    "    \n",
    "    #set hyperparameters, returns bool == success of func\n",
    "    def __setHyperParameters(self, testSize, randomState=42, learnRate=2e-5):\n",
    "        self.test_size = testSize\n",
    "        self.random_state = randomState\n",
    "        self.learn_rate = learnRate\n",
    "\n",
    "        print(f\"\\nHyperparameters Set!\\n------------------\\ntest_size:{self.test_size}\\nrandom_state:{self.random_state}\\nlearn_rate:{self.learn_rate}\")\n",
    "        return True\n",
    "    #init model, returns bool == success of func\n",
    "    def initializeModel(self, batchSize=8, maxLen=32, n_epochs=4, testSize=0.2, randomState=42, learnRate=2e-5):\n",
    "        \n",
    "        param_status, hyper_param_status = self.setParameters(batchSize, maxLen, n_epochs), self.__setHyperParameters(testSize, randomState, learnRate)\n",
    "\n",
    "        if not (param_status and hyper_param_status):\n",
    "            print(\"Initialize Failure.\")\n",
    "            return False\n",
    "\n",
    "        #self.model.to(\"mps\")\n",
    "        # Split data into training and validation sets\n",
    "        self.train_texts, self.val_texts, self.train_labels, self.val_labels = train_test_split(self.texts, self.labels, test_size=self.test_size, random_state=self.random_state)\n",
    "\n",
    "        self.val_dataset = self.CustomDataset(self.val_texts, self.val_labels, self.tokenizer, self.max_len)\n",
    "        self.val_loader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        #format sets and load dataloader\n",
    "        self.train_dataset = self.CustomDataset(self.train_texts, self.train_labels, self.tokenizer, self.max_len)\n",
    "        self.train_loader = DataLoader(self.train_dataset, self.batch_size, shuffle=True)\n",
    "\n",
    "        #init objects\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learn_rate)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        print(\"\\nModel Initialized!\\n\")\n",
    "        return True\n",
    "    \n",
    "    #no parameters will reset to default state\n",
    "    def reInitializeModel(self, batchSize=8, maxLen=32, n_epochs=10, testSize=0.2, randomState=42):\n",
    "\n",
    "        return self.initializeModel(batchSize, maxLen, n_epochs, testSize, randomState)\n",
    "\n",
    "            \n",
    "    def runModel(self):\n",
    "        #for formating so # of epochs displays properly\n",
    "        temp = (self.epochs + 1) // 10\n",
    "        count = 0\n",
    "        while temp//10 > 0:\n",
    "            temp //= 10\n",
    "            count += 1\n",
    "        headerEpochFormatStr = '-----' + str('-' *count)\n",
    "        #Table header for result data\n",
    "        print(f'\\nEpoch||Train Loss||Val Accuracy||Precision||Recall||F1 Score|')\n",
    "        print(f'{headerEpochFormatStr}||----------||------------||---------||------||--------|')\n",
    "\n",
    "\n",
    "        #for storing epoch metrics\n",
    "        epoch_metrics = []\n",
    "        # self.model.to(\"mps\")\n",
    "        # Training loop\n",
    "        self.model.train() #might need to(device) here\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            for batch in self.train_loader:\n",
    "                input_ids = batch['input_ids']\n",
    "                attention_mask = batch['attention_mask']\n",
    "                labels = batch['label']\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            avg_train_loss = total_loss / len(self.train_loader)\n",
    "\n",
    "\n",
    "            # Validation\n",
    "            val_predictions = []\n",
    "            val_true_labels = []  \n",
    "            val_accuracy = 0\n",
    "            total_val_samples = 0  \n",
    "            self.model.eval()\n",
    "            \n",
    "            for batch in self.val_loader:\n",
    "                with torch.no_grad():\n",
    "                    input_ids = batch['input_ids']\n",
    "                    attention_mask = batch['attention_mask']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    outputs = self.model(input_ids, attention_mask=attention_mask) # device?\n",
    "                    logits = outputs.logits\n",
    "                    _, predicted = torch.max(logits, dim=1)\n",
    "                    \n",
    "                    val_accuracy += (predicted == labels).sum().item()\n",
    "                    total_val_samples += labels.size(0)\n",
    "                    val_predictions.extend(predicted.cpu().numpy())\n",
    "                    val_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Convert lists to numpy arrays for sklearn metrics\n",
    "            val_predictions = np.array(val_predictions)\n",
    "            val_true_labels = np.array(val_true_labels)\n",
    "\n",
    "            # Calculate precision, recall, and F1 scores\n",
    "            precision = precision_score(val_true_labels, val_predictions, average='weighted', zero_division=1)\n",
    "            recall = recall_score(val_true_labels, val_predictions, average='weighted')\n",
    "            f1 = f1_score(val_true_labels, val_predictions, average='weighted')\n",
    "            val_accuracy /= total_val_samples\n",
    "        \n",
    "            #print eval metrics\n",
    "            print(f'{epoch+1}    ||  {avg_train_loss:.4f}  ||   {val_accuracy * 100:.2f}%   || {precision:.4f}  ||{recall:.4f}|| {f1:.4f} |')\n",
    "\n",
    "            #save metrics\n",
    "            epoch_metrics.append({'epoch': epoch, 'train_loss': avg_train_loss, 'val_accuracy': val_accuracy, 'precision': precision, 'recall': recall, 'f1':f1})\n",
    "    \n",
    "        #return metric results\n",
    "        parameters = [self.batch_size, self, self.max_len, self.epochs, self.test_size, self.random_state, self.learn_rate]\n",
    "        return self.model, [parameters, epoch_metrics]\n",
    "    #---------------------------------vvvvvvvvvvvvvvvv------------------------------------<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Basic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters Set!\n",
      "------------------\n",
      "batch_size:64\n",
      "max_len:128\n",
      "epochs:3\n",
      "\n",
      "Hyperparameters Set!\n",
      "------------------\n",
      "test_size:0.2\n",
      "random_state:42\n",
      "learn_rate:5e-05\n",
      "\n",
      "Model Initialized!\n",
      "\n",
      "\n",
      "Start Time: 2024-04-19 17:52:31.384571\n",
      "-----------------------\n",
      "\n",
      "Epoch||Train Loss||Val Accuracy||Precision||Recall||F1 Score|\n",
      "-----||----------||------------||---------||------||--------|\n",
      "1    ||  1.6603  ||   43.00%   || 0.6810  ||0.4300|| 0.3418 |\n",
      "2    ||  1.3020  ||   58.50%   || 0.7546  ||0.5850|| 0.4747 |\n",
      "3    ||  0.8801  ||   70.00%   || 0.7269  ||0.7000|| 0.6647 |\n",
      "\n",
      "End Time: 2024-04-19 17:53:31.434327, Total Runtime: 0:01:00.049756\n"
     ]
    }
   ],
   "source": [
    "test_model = bertModel()\n",
    "\n",
    "#parameters\n",
    "t_batch_size = 64  # keep below 64\n",
    "t_max_len = 128  # keep below 128\n",
    "t_epochs = 3\n",
    "#hyperparameters\n",
    "t_test_size = 0.2\n",
    "t_random_state = 42\n",
    "t_learn_rate = 5e-5 #between 1e-5 and 1e-4\n",
    "\n",
    "\n",
    "#initialize\n",
    "test_model.initializeModel(t_batch_size, t_max_len, t_epochs, t_test_size, t_random_state, t_learn_rate)\n",
    "\n",
    "start_date = datetime.now()\n",
    "print(f\"\\nStart Time: {start_date}\\n-----------------------\")\n",
    "#run the model\n",
    "trained_test_model, performance = test_model.runModel()\n",
    "\n",
    "end_date = datetime.now()\n",
    "t_runtime = (end_date-start_date)\n",
    "print(f\"\\nEnd Time: {end_date}, Total Runtime: {t_runtime}\")\n",
    "\n",
    "# print([f\"{performance[1][0]}\\n{key}: {performance[1][1][key]}\" for key in performance[1][1].keys()])\n",
    "#retrieve results\n",
    "# metricKeys = performance[1][1].keys()\n",
    "results = f\"\\n{end_date} || Runtime:{t_runtime}\\n-Parameters= batch_size:{t_batch_size}, max_len:{t_max_len}, epochs:{t_epochs}\\n-Hyperarameters= test_size:{t_test_size}, random_state:{t_random_state}, learn_rate:{t_learn_rate}\" + f\"\\nEpoch||Train Loss||Val Accuracy||Precision||Recall||F1 Score|\\n-----||----------||------------||---------||------||\" + \"\".join([f\"\\n{performance[1][i]['epoch']}    ||  {performance[1][i]['train_loss']:.4f}  ||   {performance[1][i]['val_accuracy'] * 100:.2f}%   || {performance[1][i]['precision']:.4f}  ||{performance[1][i]['recall']:.4f}|| {performance[1][i]['f1']:.4f} |\"  for i in range(len(performance[1]))])\n",
    "\n",
    "#save results\n",
    "try:\n",
    "    file = open('./bertModelResults.txt', 'a+')\n",
    "    file.seek(0,2)\n",
    "\n",
    "    pos = file.tell()\n",
    "    while pos > 0:\n",
    "        pos -= 1\n",
    "        file.seek(pos, 0)\n",
    "        if file.read(1) == '\\n':\n",
    "            break\n",
    "    \n",
    "    version_string = file.readline().strip()\n",
    "    version = int(version_string[32:len(version_string) - 2]) + 1\n",
    "    file.seek(0,2)\n",
    "    file.write(f'\\n{results}\\nEmotion Detection BERT Model v2.{version}.0')\n",
    "    file.close()\n",
    "except Exception as e:\n",
    "    print(\"\\nSave Fail: \")\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays the results of all recorded runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-19 17:46:05.216188 || Runtime:0:01:04.555742\n",
      "Parameters= batch_size:64, max_len:128, epochs:3\n",
      "Hyperarameters= test_size:0.2, random_state:42, learn_rate:5e-05\n",
      "Epoch||Train Loss||Val Accuracy||Precision||Recall||F1 Score|\n",
      "-----||----------||------------||---------||------||\n",
      "0    ||  1.5952  ||   44.50%   || 0.6488  ||0.4450|| 0.3586 |\n",
      "1    ||  1.3514  ||   57.00%   || 0.7295  ||0.5700|| 0.4588 |\n",
      "2    ||  0.9027  ||   67.00%   || 0.6582  ||0.6700|| 0.6175 |\n",
      "Emotion Detection BERT Model v2.0.0\n",
      "\n",
      "2024-04-19 17:53:31.434327 || Runtime:0:01:00.049756\n",
      "-Parameters= batch_size:64, max_len:128, epochs:3\n",
      "-Hyperarameters= test_size:0.2, random_state:42, learn_rate:5e-05\n",
      "Epoch||Train Loss||Val Accuracy||Precision||Recall||F1 Score|\n",
      "-----||----------||------------||---------||------||\n",
      "0    ||  1.6603  ||   43.00%   || 0.6810  ||0.4300|| 0.3418 |\n",
      "1    ||  1.3020  ||   58.50%   || 0.7546  ||0.5850|| 0.4747 |\n",
      "2    ||  0.8801  ||   70.00%   || 0.7269  ||0.7000|| 0.6647 |\n",
      "Emotion Detection BERT Model v2.1.0\n"
     ]
    }
   ],
   "source": [
    "total_data = open('./bertModelResults.txt', 'r')\n",
    "total_data_str = total_data.read()\n",
    "total_data.close()\n",
    "print(total_data_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Optimal Parameters\n",
    "### Metrics:\n",
    "- ????\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
